---
title: "ASR Code Examples"
description: "Working code examples for implementing the ASR WebSocket API"
icon: "compact-disc"
---

# Non-Streaming Transcription using Python SDK

Use the official Python SDK to transcribe complete files without streaming.

<CodeGroup>

```python Sync
import os
from smallestai.waves import WavesClient

api_key = os.getenv("SMALLEST_API_KEY")
client = WavesClient(api_key)

result = client.transcribe(
    file_path="path/to/audio.wav",
    language="en",
    word_timestamps=False,
    age_detection=False,
    gender_detection=False,
    emotion_detection=False
)
print(result)
```

```python Async
import os
import asyncio
from smallestai.waves import AsyncWavesClient

api_key = os.getenv("SMALLEST_API_KEY")
client = AsyncWavesClient(api_key)

result = await client.transcribe(
    file_path="path/to/audio.wav",
    language="en",          
    word_timestamps=False,   
    emotion_detection=False, 
    gender_detection=False,  
    age_detection=False,    
    model="lightning"       
)

print(result)
```

</CodeGroup>


# ASR Streaming - WebSocket Code Examples

This guide provides complete working examples for implementing the Waves ASR WebSocket API across different platforms and use cases.

## Server-Side Implementations

<CodeGroup>

```python python 
import asyncio
import websockets
import json

class FileStreamer:
    def __init__(self, api_key, audio_file):
        self.api_key = api_key
        self.audio_file = audio_file
        self.ws = None
        self.connected = False
        self.transcription_text = []
        
        self.audio_data = open(self.audio_file, 'rb').read()

    async def connect(self):
        base_url = "wss://waves-api.smallest.ai/api/v1/asr"
        
        self.params = {
            "audioLanguage": "en",
            "audioEncoding": "linear16",
            "audioSampleRate": "16000",
            "audioChannels": "1",
            "addPunctuation": "true",
            "api_key": self.api_key
        }
        
        query_string = "&".join([f"{key}={value}" for key, value in self.params.items()])
        url = f"{base_url}?{query_string}"
        
        print("üîå Connecting...")
        
        self.ws = await websockets.connect(url)
        print("‚úÖ Connected")
        self.connected = True
        self.listener_task = asyncio.create_task(self._listen_for_messages())

    async def _listen_for_messages(self):
        try:
            async for message in self.ws:
                response = json.loads(message)
                if "error" in response:
                    print(f"‚ùå Error: {response}")
                elif "text" in response:
                    end_marker = " [END]" if response.get("isEndOfTurn", False) else ""
                    print(f"üìù {response['text']}{end_marker}")
                    self.transcription_text.append(response["text"])
        except websockets.exceptions.ConnectionClosed:
            print("üîå Connection closed")
            self.connected = False

    async def stream_file(self):      
        CHUNK_SIZE_S = 0.3 # in seconds
        
        chunk_size = int(16000 * 2 * CHUNK_SIZE_S) # change sample rate here
        
        while len(self.audio_data):
            chunk, self.audio_data = self.audio_data[:chunk_size], self.audio_data[chunk_size:]
            await self.ws.send(chunk)
            await asyncio.sleep(CHUNK_SIZE_MS)
    
        print("‚úÖ Streaming complete")
        await self.ws.send(b'')

    async def get_transcription(self):
        return " ".join(self.transcription_text)

    async def close(self):
        if self.ws:
            await self.ws.close()

async def main():
    api_key = "SMALLEST_API_KEY"
    audio_file = "audio_path.wav"
    
    streamer = FileStreamer(api_key, audio_file)
    
    try:
        await streamer.connect()
        await streamer.stream_file()
        if streamer.listener_task:
            await streamer.listener_task
        
        full_text = await streamer.get_transcription()
        print(f"\nüéØ Complete Transcription:\n{full_text}")
        
    except Exception as error:
        print(f"‚ùå Error: {error}")
    finally:
        await streamer.close()

if __name__ == "__main__":
    asyncio.run(main())
```

```javascript node.js
const WebSocket = require('ws');
const fs = require('fs');
const url = require('url');

class FileStreamer {
  constructor(apiKey, audioFile) {
    this.apiKey = apiKey;
    this.audioFile = audioFile;
    this.ws = null;
    this.connected = false;
    this.transcriptionText = [];
    this.audioData = fs.readFileSync(this.audioFile);
  }

  async connect() {
    const baseUrl = "wss://waves-api.smallest.ai/api/v1/asr";
    const params = {
      audioLanguage: "en",
      audioEncoding: "linear16",
      audioSampleRate: "16000",
      audioChannels: "1",
      addPunctuation: "true",
      api_key: this.apiKey
    };

    const query = new url.URLSearchParams(params).toString();
    const fullUrl = `${baseUrl}?${query}`;

    console.log("üîå Connecting...");

    this.ws = new WebSocket(fullUrl);

    return new Promise((resolve, reject) => {
      this.ws.onopen = () => {
        console.log("‚úÖ Connected");
        this.connected = true;
        this.ws.onmessage = (event) => this._handleMessage(event);
        this.ws.onclose = () => {
          console.log("üîå Connection closed");
          this.connected = false;
        };
        this.ws.onerror = (error) => {
          console.log("‚ùå WebSocket error:", error.message);
          reject(error);
        };
        resolve();
      };
    });
  }

  _handleMessage(event) {
    try {
      const response = JSON.parse(event.data);
      if (response.error) {
        console.log(`‚ùå Error: ${JSON.stringify(response)}`);
      } else if (response.text) {
        const endMarker = response.isEndOfTurn ? " [END]" : "";
        console.log(`üìù ${response.text}${endMarker}`);
        this.transcriptionText.push(response.text);
      }
    } catch (error) {
      console.error("‚ùå Failed to parse message:", error);
    }
  }

  async streamFile() {
    const CHUNK_SIZE_MS = 0.3;
    const sampleRate = parseInt(this.params.audioSampleRate, 10);
    const chunkSizeBytes = Math.floor(sampleRate * 2 * CHUNK_SIZE_MS);

    let offset = 0;
    while (offset < this.audioData.length) {
      const end = Math.min(offset + chunkSizeBytes, this.audioData.length);
      const chunk = this.audioData.slice(offset, end);
      this.ws.send(chunk);
      offset = end;
      await new Promise(resolve => setTimeout(resolve, CHUNK_SIZE_MS * 1000));
    }

    console.log("‚úÖ Streaming complete");
    this.ws.send('');
  }

  async getTranscription() {
    return this.transcriptionText.join(" ");
  }

  close() {
    if (this.ws) {
      this.ws.close();
    }
  }
}

async function main() {
  const apiKey = "SMALLEST_API_KEY";
  const audioFile = "audio_path.wav";

  const streamer = new FileStreamer(apiKey, audioFile);

  try {
    await streamer.connect();
    await streamer.streamFile();

    // Wait for the transcription to complete
    await new Promise(resolve => {
      streamer.ws.onclose = () => {
        resolve();
      };
    });

    const fullText = await streamer.getTranscription();
    console.log(`\nüéØ Complete Transcription:\n${fullText}`);
  } catch (error) {
    console.error(`‚ùå Error: ${error.message}`);
  } finally {
    streamer.close();
  }
}

main();
```
</CodeGroup>

## JavaScript (Browser with Microphone)

Complete example for browser-based real-time transcription:

<CodeGroup>

```javascript Browser ASR Implementation
// Browser-based ASR with microphone input
let ws;
let audioContext;
let processor;
let source;
let stream;

async function startASR() {
    const apiKey = 'your-api-key';  // Replace with your API key
    const baseUrl = 'wss://waves-api.smallest.ai/api/v1/asr';
    
    // Configure parameters
    const params = new URLSearchParams({
        api_key: apiKey,
        audioEncoding: 'linear16',
        audioSampleRate: '16000',
        audioChannels: '1',
        addPunctuation: 'true',
        speechEndpointing: '300'
    });
    
    const url = `${baseUrl}?${params}`;
    ws = new WebSocket(url);

    ws.onopen = async () => {
        console.log('‚úÖ Connected to ASR service');
        await setupMicrophone();
    };

    ws.onmessage = (event) => {
        try {
            const response = JSON.parse(event.data);
            handleTranscription(response);
        } catch (err) {
            console.error('‚ùå Parse error:', err);
        }
    };

    ws.onerror = (error) => {
        console.error('‚ùå WebSocket error:', error);
    };

    ws.onclose = (event) => {
        console.log(`üîå Connection closed: ${event.code} - ${event.reason}`);
        stopASR();
    };
}

async function setupMicrophone() {
    try {
        // Request microphone access
        stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: 16000,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
            }
        });

        // Create audio context
        audioContext = new AudioContext({ sampleRate: 16000 });
        source = audioContext.createMediaStreamSource(stream);
        
        // Create audio processor
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        processor.onaudioprocess = (e) => {
            if (ws.readyState === WebSocket.OPEN) {
                const inputData = e.inputBuffer.getChannelData(0);
                
                // Convert to 16-bit PCM
                const int16Data = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    int16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                }
                
                // Send audio data
                ws.send(int16Data.buffer);
            }
        };

        // Connect audio nodes
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        console.log('üé§ Recording started. Speak now...');
        
    } catch (err) {
        console.error('‚ùå Microphone error:', err);
        alert('Microphone access required for ASR functionality');
    }
}

function handleTranscription(response) {
    console.log('üìù Response:', response);
    
    if (response.error) {
        console.error('‚ùå API Error:', response);
        return;
    }
    
    if (response.text) {
        const endOfTurn = response.isEndOfTurn ? ' [END_OF_TURN]' : '';
        console.log(`üìù ${response.text}${endOfTurn}`);
        updateTranscriptionDisplay(response.text);
    }
}

function updateTranscriptionDisplay(text) {
    const container = document.getElementById('transcription');
    if (!container) return;

    const finalDiv = document.createElement('div');
    finalDiv.className = 'final-transcription';
    finalDiv.textContent = text;
    container.appendChild(finalDiv);
}

function stopASR() {
    if (processor) {
        processor.disconnect();
        processor = null;
    }
    if (source) {
        source.disconnect();
        source = null;
    }
    if (audioContext) {
        audioContext.close();
        audioContext = null;
    }
    if (stream) {
        stream.getTracks().forEach(track => track.stop());
        stream = null;
    }
    if (ws) {
        ws.close();
        ws = null;
    }
    console.log('‚èπÔ∏è ASR stopped');
}

// Usage
document.addEventListener('DOMContentLoaded', () => {
    const startBtn = document.getElementById('start-asr');
    const stopBtn = document.getElementById('stop-asr');
    
    startBtn?.addEventListener('click', startASR);
    stopBtn?.addEventListener('click', stopASR);
});
```

```html HTML Setup
<!DOCTYPE html>
<html>
<head>
    <title>Waves ASR Demo</title>
    <style>
        .final-transcription {
            color: #000;
            margin: 5px 0;
            padding: 8px;
            background: #f0f0f0;
            border-radius: 4px;
        }
        
        #transcription {
            height: 300px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            margin: 10px 0;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        #start-asr { background: #28a745; color: white; }
        #stop-asr { background: #dc3545; color: white; }
    </style>
</head>
<body>
    <h1>Waves ASR Demo</h1>
    <button id="start-asr">Start Recording</button>
    <button id="stop-asr">Stop Recording</button>
    <div id="transcription"></div>
    
    <script src="asr-demo.js"></script>
</body>
</html>
```

</CodeGroup>
