---
title: 'Word timestamps'
description: 'Return word-level timing metadata from Lightning STT WebSocket API'
---

## Learn how to enable word timestamps

Add `word_timestamps=true` to your WebSocket connection query parameters when connecting to the Lightning STT WebSocket API.

## Output format & field of interest

When enabled, responses include a `word_timestamps` array with `word`, `start`, and `end` fields. Use these offsets to generate captions, subtitle tracks, or to align transcripts with downstream analytics.

## Sample connection

```javascript
const url = new URL("wss://waves-api.smallest.ai/api/v1/lightning/get_text");
url.searchParams.append("language", "en");
url.searchParams.append("encoding", "linear16");
url.searchParams.append("sample_rate", "16000");
url.searchParams.append("word_timestamps", "true");

const ws = new WebSocket(url.toString(), {
  headers: {
    Authorization: `Bearer ${API_KEY}`,
  },
});
```

## Sample response

```json
{
  "session_id": "sess_12345abcde",
  "transcript": "Hello, how are you?",
  "full_transcript": "Hello, how are you?",
  "is_final": true,
  "is_last": false,
  "language": "en",
  "word_timestamps": [
    {
      "word": "Hello",
      "start": 0.0,
      "end": 0.5
    },
    {
      "word": "how",
      "start": 0.6,
      "end": 0.8
    },
    {
      "word": "are",
      "start": 0.8,
      "end": 1.0
    },
    {
      "word": "you?",
      "start": 1.0,
      "end": 1.3
    }
  ]
}
```

## Response fields

| Field | Type | Description |
|-------|------|-------------|
| `word` | string | The transcribed word |
| `start` | number | Start time in seconds |
| `end` | number | End time in seconds |

## Use cases

- **Caption generation**: Create synchronized captions for video or live streams
- **Subtitle tracks**: Generate SRT or VTT subtitle files
- **Analytics**: Align transcripts with audio playback for detailed analysis
- **Search**: Enable time-based search within audio content


