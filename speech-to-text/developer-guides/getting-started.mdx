---
title: 'Quickstart'
description: 'Send your first Lightning ASR POST request using curl, Python, or JavaScript'
---

The Lightning ASR POST API converts speech to text using either raw audio bytes or URLs that point to hosted audio files. Follow the steps below to authenticate, choose an input method, and send your first request.

## Prerequisites

- Waves API key (`Authorization: Bearer YOUR_API_KEY`)
- `curl` for quick tests
- Optional: Python 3.9+ with `requests`, or Node.js 18+ for programmatic examples

## Steps

<Steps>
  <Step title="Create an API key">
    Generate a Lightning ASR key in the Waves dashboard and store it in a secure secret manager or environment variable (`SMALLEST_API_KEY`).
  </Step>
  <Step title="Choose your input method">
    Use raw audio bytes when you can upload the media directly, or JSON payloads when the file is already hosted.

    | Method | Content-Type | When to use |
    | --- | --- | --- |
    | Raw bytes | `audio/wav`, `application/octet-stream`, etc. | CLI scripts, backend services that have the file on disk |
    | Audio URL | `application/json` | Workflows where the audio lives in cloud storage |
  </Step>
  <Step title="Make the request (curl)">
    <CodeGroup>
```bash Raw bytes
curl --request POST \
  --url "https://waves-api.smallest.ai/api/v1/lightning/get_text?model=lightning&language=en&word_timestamps=true" \
  --header "Authorization: Bearer $SMALLEST_API_KEY" \
  --header "Content-Type: audio/wav" \
  --data-binary "@/path/to/audio.wav"
```
```bash Audio URL
curl --request POST \
  --url "https://waves-api.smallest.ai/api/v1/lightning/get_text?model=lightning&language=multi&word_timestamps=true" \
  --header "Authorization: Bearer $SMALLEST_API_KEY" \
  --header "Content-Type: application/json" \
  --data '{"url":"https://example.com/audio.mp3"}'
```
    </CodeGroup>
  </Step>
  <Step title="Integrate in code">
    <CodeGroup>
```python Python (raw bytes)
import os
import requests

API_KEY = os.environ["SMALLEST_API_KEY"]
endpoint = "https://waves-api.smallest.ai/api/v1/lightning/get_text"
params = {
    "model": "lightning",
    "language": "en",
    "word_timestamps": "true",
    "diarize": "true",
}
headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "audio/wav",
}
with open("sample.wav", "rb") as audio:
    response = requests.post(endpoint, params=params, headers=headers, data=audio.read(), timeout=120)
response.raise_for_status()
print(response.json()["transcription"])
```
```javascript JavaScript (audio URL)
import fetch from "node-fetch";

const endpoint = "https://waves-api.smallest.ai/api/v1/lightning/get_text";
const params = new URLSearchParams({
  model: "lightning",
  language: "multi",
  word_timestamps: "true",
  diarize: "true",
});

const response = await fetch(`${endpoint}?${params}`, {
  method: "POST",
  headers: {
    Authorization: `Bearer ${process.env.SMALLEST_API_KEY}`,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({ url: "https://example.com/audio.mp3" }),
});

if (!response.ok) throw new Error(await response.text());
const data = await response.json();
console.log(data.transcription);
```
    </CodeGroup>
  </Step>
</Steps>

## Inspect the response

Successful requests return a JSON payload containing `transcription`, `word_timestamps`, `utterances`, optional `age`/`gender`/`emotions`, and `metadata` (filename, duration, file size). See the [full response example](/speech-to-text/overview#response-payload) for details.

## Next steps

- Tune audio formats with the [ASR input & preprocessing guide](/speech-to-text/developer-guides/audio-prep).
- Add retries, logging, and error handling references from [best practices](/speech-to-text/developer-guides/best-practices) and [troubleshooting](/speech-to-text/developer-guides/troubleshooting).
- Benchmark quality using the [evaluation playbook](/speech-to-text/evaluation/how-to).