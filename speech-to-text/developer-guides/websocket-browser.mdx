---
title: 'ASR WebSocket â€“ Browser microphone'
description: 'Capture microphone audio in the browser and stream it to Waves ASR'
---

# Browser microphone example

> Build a web experience that records microphone audio, streams it over WebSocket, and renders live transcripts.

This guide complements the core [ASR WebSocket API](/speech-to-text/developer-guides/websocket-api) by focusing on front-end capture, audio conversion, and UI updates.

## Architecture overview

1. Client requests microphone access via `navigator.mediaDevices.getUserMedia`.
2. Audio samples flow through the Web Audio API, downsampled to 16 kHz mono.
3. Samples are converted to 16-bit PCM and sent to the backend WebSocket (ideally proxied to attach the API key securely).
4. Incoming messages update the transcription UI with partial and final text.

## JavaScript implementation

```javascript asr-demo.js
let ws;
let audioContext;
let processor;
let source;
let stream;

async function startASR() {
  const baseUrl = "/api/asr-proxy"; // proxy endpoint that adds Authorization header
  ws = new WebSocket(baseUrl);

  ws.onopen = async () => {
    console.log("âœ… Connected to ASR service");
    await setupMicrophone();
  };

  ws.onmessage = (event) => {
    const response = JSON.parse(event.data);
    handleTranscription(response);
  };

  ws.onerror = (error) => {
    console.error("âŒ WebSocket error:", error);
  };

  ws.onclose = () => {
    console.log("ðŸ”Œ Connection closed");
    stopASR();
  };
}

async function setupMicrophone() {
  stream = await navigator.mediaDevices.getUserMedia({
    audio: {
      sampleRate: 16000,
      channelCount: 1,
      echoCancellation: true,
      noiseSuppression: true,
    },
  });

  audioContext = new AudioContext({ sampleRate: 16000 });
  source = audioContext.createMediaStreamSource(stream);
  processor = audioContext.createScriptProcessor(4096, 1, 1);

  processor.onaudioprocess = (event) => {
    if (ws.readyState !== WebSocket.OPEN) return;
    const input = event.inputBuffer.getChannelData(0);
    const pcm16 = new Int16Array(input.length);
    for (let i = 0; i < input.length; i++) {
      pcm16[i] = Math.max(-32768, Math.min(32767, input[i] * 32768));
    }
    ws.send(pcm16.buffer);
  };

  source.connect(processor);
  processor.connect(audioContext.destination);
  console.log("ðŸŽ¤ Recording started");
}

function handleTranscription(response) {
  if (response.error) {
    console.error("âŒ API error:", response);
    return;
  }
  if (response.text) {
    const tag = response.isEndOfTurn ? " [END]" : "";
    console.log(`ðŸ“ ${response.text}${tag}`);
    updateTranscriptionDisplay(response.text);
  }
}

function updateTranscriptionDisplay(text) {
  const container = document.getElementById("transcription");
  if (!container) return;
  const entry = document.createElement("div");
  entry.className = "final-transcription";
  entry.textContent = text;
  container.appendChild(entry);
}

function stopASR() {
  processor?.disconnect();
  source?.disconnect();
  audioContext?.close();
  stream?.getTracks().forEach((track) => track.stop());
  ws?.close();
  processor = source = audioContext = stream = ws = null;
  console.log("â¹ï¸ ASR stopped");
}

document.addEventListener("DOMContentLoaded", () => {
  document.getElementById("start-asr")?.addEventListener("click", startASR);
  document.getElementById("stop-asr")?.addEventListener("click", stopASR);
});
```

## HTML scaffold

```html index.html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Waves ASR Demo</title>
    <style>
      .final-transcription {
        color: #111;
        margin: 6px 0;
        padding: 8px;
        background: #f5f5f5;
        border-radius: 4px;
      }
      #transcription {
        height: 280px;
        overflow-y: auto;
        border: 1px solid #ddd;
        padding: 12px;
      }
      button {
        padding: 10px 20px;
        margin: 5px;
        border: none;
        border-radius: 4px;
        cursor: pointer;
      }
      #start-asr {
        background: #16a34a;
        color: #fff;
      }
      #stop-asr {
        background: #dc2626;
        color: #fff;
      }
    </style>
  </head>
  <body>
    <h1>Waves ASR Demo</h1>
    <button id="start-asr">Start Recording</button>
    <button id="stop-asr">Stop Recording</button>
    <div id="transcription"></div>
    <script src="asr-demo.js"></script>
  </body>
</html>
```

## Deployment considerations

- **API keys** â€“ never expose secrets client-side. Proxy WebSocket requests through your backend to inject `Authorization`.
- **Resampling** â€“ ensure your proxy forwards audio as 16-bit PCM at 16 kHz (or match the format declared in query params).
- **Browser compatibility** â€“ `ScriptProcessorNode` is widely supported but consider migrating to `AudioWorklet` for lower latency on modern browsers.
- **Accessibility** â€“ render transcripts in real time for screen readers and provide controls to pause/stop recording.

